<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Stanford University EDUC463/CS432: Computer Vision for Education and Social Science Research</title>

  <!-- bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css">

  <!-- Google fonts -->
  <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" type="text/css" href="style.css" />

 </head>

<div id="header">

    <a href="http://stanford.edu/">
    <img src="images/stanfordlogo.jpg" style="height:50px; float: right; margin-right: 20px;"><br>
  </a>
  <br>
 <h1>EDUC463 (CS432): Computer Vision for Education and Social Science Research</h1>
  <div class='text-center'>
    <h3>Winter 2023</h3>
  </div>
  <div class='text-center'>
    <h3>Instructor: Nick Haber
    </h3>
    <h3>TA: Eric Zelikman
    </h3>
  </div>
  <div class='text-center'>
    <h3>Meeting times: Mo, We 4:30 - 5:30PM</h3>
    <h3>Location: 160-124</h3>
  </div>
  <div class='text-center'>
    <!-- Calendly: https://calendly.com/ezelikman/oh -->
    <h3>Eric's Office Hours: Tuesday 4:30 - 5:50PM in-person, 5:30-7:30 bookable
    <a href="https://calendly.com/ezelikman/oh" target="_blank" rel="noopener noreferrer">here</a>
    </h3>
    <h3>Location: CERAS</h3>
  </div>


  <div style="clear:both;"></div>
</div>

<div id="teaser">
	<img src="images/4_image_crop.png" alt="Summary image here" style="width:60%;"
	 class = "center">

</div>

<div class="sechighlight">
<div class="container sec">
  <h2>Course Description</h2>

  <div id="coursedesc">
<p>
Computer vision -- the study of how to design artificial systems that can perform high-level tasks related to image or video data (e.g. recognizing and locating objects in images and behaviors in videos, or generating photorealistic, imagined data) -- has seen dramatic successes in recent years. In this course, we seek to give education and social science researchers the know-how needed to apply cutting edge computer vision algorithms in their work as well as an opportunity to workshop applications in their domains of interest. Particular application domains of interest include (1) building computer vision-powered tools which can be applied in educational settings, and (2) the analysis of human behavioral data. However, this course is meant to be useful for a wide variety of use cases, and aspects of it can be tailored to individual interest. Students will complete a <a href="projects.html" target="_blank" rel="noopener noreferrer">project component</a> where they will apply such a technique in a domain of their choosing.</p>

<p>This course is part lecture (in which I give a survey of computer vision tools and explain the basics of their inner workings), part seminar (in which we workshop a wide variety of application ideas, many student-inspired), and part workshop/lab (in which we prototype applications). We'll look to draw from the students taking the course for application ideas, but to give you a sense, here are a few prime examples:</p>
  <ul>
    <li>Education and social science research often uses, or could gainfully use, video data, which is manually coded by researchers (often for high-level semantic content, e.g. engagement or affect). In some cases, computer vision has the capability of automating large aspects of this process. In other cases, it has the potential to aid manual coding, greatly reducing the effort of researchers. In either case, it may be possible to drastically increase the scale of data analysis as well as add a wide variety of additional quantitative metrics.</li>
    <li>A wide variety of computer vision techniques (e.g. affect recognition, object recognition, and object localization) have promising applications in educational technologies. For example, in previous work, I and many others worked on a computer-vision powered tool for children with autism using Google Glass. There is tremendous opportunity to prototype new tools, toys, and aids.</li>
    <li>Recent and ongoing advances in foundation models, and in particular, generative AI, present a wide range of opportunities for developing novel content, and for students to interact with, learn from, and learn with AI in new ways.</li>
  </ul>

<h2>FAQ</h2>
<h3>Who is this class for?</h3> 
<p>It's useful for you to have some background in programming, though we will tailor the course and scope projects so that it is suitable for a wide variety of backgrounds. Most importantly, you should be interested in these sorts of applications! Stanford offers a number of excellent computer sciences centered on computer vision, and we'll look to distinguish this one for the opportunity to workshop and prototype application ideas. In the past, this course has been useful for applications-oriented students who either do not have the bandwidth for a course like <a href="http://cs231n.stanford.edu/"  target="_blank" rel="noopener noreferrer">CS231N</a>, or who wish to take it concurrently or in the future.</p>

<h3>What's computer vision?</h3>
<a href="https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e" target="_blank" rel="noopener noreferrer">Here</a> is a high-level blog post about it and its many capabilities. Note: this is from 2019, which leaves out some recent advances! <a href="https://medium.com/the-modern-scientist/a-primer-on-generative-ai-839c06431f3e" target="_blank" rel="noopener noreferrer">Here</a> is a more recent blog post specialized to generative AI.

<h3>Do I need to come in with a dataset or particular application in mind?</h3>
No! These are welcome, but we'll work together to find useful data with which to play.

<h3>What level of coding is involved?</h3>
We'll look to make this accessible to those with a wide variety of backgrounds. By then end, we hope you'll be able to take existing computer vision tools (either high-level tools, like those provided by Google AI Platform, or lower level, like someone's GitHub repo), try them out in some new application, and troubleshoot if they do not work. So this will likely be less demanding than CS vision courses (and perhaps a good stepping stone to them), and if you are, for example, comfortable manipulating and analyzing data in some language, and have at least some familiarity with python, this course could work well for you. In the past, several students built their projects off of <a href= "https://www.tensorflow.org/tutorials" target="_blank" rel="noopener noreferrer">Tensorflow Colab Demos</a>, which are run in the browser, whereas others found custom software or GitHub repose that worked well for their projects.
  </div>
</div>
</div>

<div class="container sec">
  <h2>Prerequisites</h2>
  <p>This course is intended to attract a broad range of students interested in applying these methods, and in particular students who do not have significant experience taking computer science courses. <a href="projects.html" target="_blank" rel="noopener noreferrer">Project milestones</a> will be tailored so as to be appropriate for each student’s background, and we'll make sure you feel supported in all technical aspects.

  <ul>
    <li><span class="spanh">Students should have some experience in at least one programming language. It's helpful to be able to find one's way around simple python scripts, but if you're strongly motivated, you should be able to pick up the needed basics.</li>
    <li><span class="spanh">A working knowledge in linear algebra, calculus, data science, and statistics (MATH 19, 41, or 51, EDUC400b, 423, 423a, or equivalent) is useful but not at all required.</li>
  </ul>
</div>

<div class="sechighlight">
<div class="container sec">
  <div class="row">
    <div class="col-md-3">
      <h2>Meeting details</h2>
      Winter quarter, 2022<br>
      Mo, We 4:30-5:50PM<br>
      Building 160 rm 124<br>
    </div>
    <div class="col-md-3">
      <h2>Office hours</h2>
      Eric: Tuesday 4:30-5:30PM at CERAS, and 5:30-7:30 bookable <a href="https://calendly.com/ezelikman/oh" target="_blank" rel="noopener noreferrer">here</a><br>
      <br>
      <a href="mailto:nhaber@stanford.edu">nhaber@stanford.edu</a>
      <a href="mailto:ezelikma@stanford.edu">ezelikma@stanford.edu</a>

    </div>
    <div class="col-md-3">
      <h2>Forum, project submissions</h2>
        Visit our <a href="https://canvas.stanford.edu/courses/166476" target="_blank" rel="noopener noreferrer">Canvas page.</a>
    </div>
<!--     <div class="col-md-4">
      <h2>Readings</h2>
      Detailed <a href="readings.html">readings & syllabus</a> page.<br>
      Required readings in <b>bold</b>.<br>
      Contents subject to change.
    </div>
 -->    <div class="col-md-3">
      <h2>Grading</h2>
      <a href="projects.html" target="_blank" rel="noopener noreferrer">Project</a> presentation and report 30%<br>
      Earlier project milestones 30%<br>
      Homework 20%<br>
      Discussion participation 20%
    </div>
<!--     <div class="col-md-4">
      <h2>Resources</h2>
    <a href="talk_faq.html">Hints/expectations</a> for giving presentations.<br>
    <a href="projects.html">Project timeline</a>.<br>
    Have a look at some helpful <a href="resources.html">resources</a><br>
    for relevant blog posts,<br> environments, and codebases.<br>
    This will grow throughout the quarter<br> as we find new ones!
    </div>
 -->  </div>
</div>
</div>

<div class="container sec">
  <h2>Learning objectives & student responsibilities</h2>
<p>Students should walk away from the course with three general skills:</p>
  <ul>
    <li><span class="spanh">A basic familiarity with a wide variety of successful computer vision tools,</li>
    <li><span class="spanh">enough fluency in the field so that, for a particular application, they can attempt to find a suitable computer vision tool, locate a codebase or API for it, and apply it in their setting, and</li>
    <li><span class="spanh">the ability to troubleshoot, and in some cases adapt, their computer vision applications.</li>
  </ul>


  <div id="studentresp">
<p>Each student will complete a project in which they will apply computer vision to a domain of their choosing. See <a href="projects.html" target="_blank" rel="noopener noreferrer">here</a> for project details. In additiod, each student will complete two assignments.
</div>
</div>


<div class="container sec">
  <h2>Resources:</h2>
	<a href="https://gist.github.com/ezelikman/3ab568c1725969312367b3f802d9fee0">Glossary</a>
	<a href="https://drive.google.com/drive/folders/1KLoqMxYfr_jpued1niLFGSi0Qf6VrqS6?usp=sharing">Notebooks</a>
</div>
	
<div class="sechighlight">
<div class="container sec">
  <h2>Topics at-a-glance</h2>
  <p>Topics and schedule subject to modifications. Note that not all <a href="projects.html" target="_blank" rel="noopener noreferrer">project milestones</a> are displayed here.</p>
<h3>Unit 1: Getting started</h3>
<p>We take a first look at what is possible with computer vision with a high-level survey of current techniques. We'll point you to resources for getting started, discuss ethical considerations, and have first pitches for projects.</p>
  <ul>
    <li>Class 1 (Jan 9): Introduction: what is computer vision? Syllabus and logistics</li>
    <li>Class 2 (Jan 11): A whirlwind tour of computer vision</li>
    <li>Class 3 (Jan 18): Resources and getting started</li>
    <li>Class 4 (Jan 23): Practicum</li>
    <li>Class 5 (Jan 25): Ethical considerations</li>
    <l1>Class 6 (Jan 30): Project scoping pitches</l1>
  </ul>
<h3>Unit 2: Inner workings and practicalities.</h3>
<p>The goal of this class is not to be able to implement all of the above algorithms ourselves. However, in applying any of these, it is useful to have some intuition for how they work. Fortunately, many current methods have a great deal of commonality. Hence, here we will look in some detail at how image classification works, with practice being able to train such algorithms. We will then have a tutorial on other techniques.</p>
  <ul>
    <li>Class 7 (Feb 1): Image classification: lecture and practicum interwoven, pt 1</li>
    <li>Class 8 (Feb 6): More “classical” models: lecture and practicum interwoven, pt 3</li>
    <li>Class 9 (Feb 8): Practicalities of data and model access</li>
    <li>Class 10 (Feb 13): Self-supervision, foundation models, generative models lecture</li>
    <li>Class 11 (Feb 15): Self-supervision, foundation models, generative models practicum</li>
    <li>Class 12 (Feb 22): Project update workshopping</li>
  </ul>
<h3>Unit 3: A selection of computer vision applications</h3>
<p>Here, we will have a series of lectures and discussions on current applications of computer vision in education and the social sciences.</p>
  <ul>
    <li>Class 13 (Feb 27): The Autism Glass Project</li>
    <li>Class 14 (Mar 1): iFIND</li>
    <li>Class 15 (Mar 6): The Human Screenome Project</li>
    <li>Class 16 (Mar 8): TBA</li>
    <li>Class 17 (Mar 13): Student final presentations, pt 1</li>
    <li>Class 18 (Mar 15): Student final presentations, pt 2</li>
  </ul>
</div>
</div>


</html>















