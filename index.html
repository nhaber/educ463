<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Stanford University CS422: Interactive and Embodied Learning</title>

  <!-- bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css">

  <!-- Google fonts -->
  <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" type="text/css" href="style.css" />

 </head>

<div id="header">

    <a href="http://stanford.edu/">
    <img src="images/stanfordlogo.jpg" style="height:50px; float: right; margin-right: 20px;"><br>
  </a>
  <br>
 <h1>EDUC463: Computer Vision for Education and Social Science Research</h1>
  <div class='text-center'>
    <h3>Spring 2021</h3>
  </div>
  <div class='text-center'>
    <h3>Instructors: Nick Haber (lead) and Victoria Delaney (TA)
    </h3>
  <div class='text-center'>
    <h3>Meeting times: Mo, We 8:30 - 9:50 AM (Zoom details forthcoming on Canvas page)
    </h3>
  </div>



  <div style="clear:both;"></div>
</div>

<div id="teaser">
	<img src="images/4_image_crop.png" alt="Summary image here" style="width:60%;"
	 class = "center">

</div>

<div class="sechighlight">
<div class="container sec">
  <h2>Course Description</h2>

  <div id="coursedesc">
<p>Computer vision -- the study of how to design artificial systems that can perform high-level tasks related to image or video data (e.g. recognizing and locating objects in images and behaviors in videos, or generating photorealistic, imagined data) -- has seen dramatic successes in recent years. In this course, we seek to give education and social science researchers the know-how needed to apply cutting edge computer vision algorithms in their work as well as an opportunity to workshop applications in their domains of interest. Particular application domains of interest include (1) building computer vision-powered tools which can be applied in educational settings, and (2) the analysis of human behavioral data. However, this course is meant to be useful for a wide variety of use cases, and aspects of it can be tailored to individual interest. Students will complete assignments which walk them through the basics of applying, troubleshooting, and adapting existing algorithms, as well as a project component where they will apply such a technique in a domain of their choosing.</p>

<p>The first iteration of this course will be part lecture (in which I give a survey of computer vision tools and explain the basics of their inner workings), part seminar (in which we workshop a wide variety of application ideas, many hopefully student-inspired), and part lab (in which we prototype applications). We'll look to draw from the students taking the course for application ideas, but to give you a sense, here are a couple of prime examples:</p>
  <ul>
    <li>Education and social science research often uses, or could gainfully use, video data, which is manually coded by researchers (often for high-level semantic content, e.g. engagement or affect). In some cases, computer vision has the capability of automating large aspects of this process. In other cases, it has the potential to aid manual coding, greatly reducing the effort of researchers. In either case, it may be possible to drastically increase the scale of data analysis as well as add a wide variety of additional quantitative metrics.</li>
    <li>A wide variety of computer vision techniques (e.g. affect recognition, object recognition, and object localization) have promising applications in educational technologies. For example, in previous work, I and many others worked on a computer-vision powered tool for children with autism using Google Glass. There is tremendous opportunity to prototype new tools, toys, and aids.</li>
  </ul>

<h2>FAQ</h2>
<h3>Who is this class for?</h3> 
<p>It's very useful for you to have some background in programming, though we will tailor the course and scope projects so that it is suitable for a wide variety of backgrounds. Most importantly, you should be interested in these sorts of applications! Stanford offers a number of excellent computer sciences centered on computer vision, and we'll look to distinguish this one for the opportunity to workshop and prototype application ideas.</p>

<h3>What's computer vision?</h3>
<a href="https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e" target="_blank" rel="noopener noreferrer">Here</a> is a high-level blog post about it and its many capabilities.

<h3>Do I need to come in with a dataset or particular application in mind?</h3>
No! These are welcome, but we'll work together to find useful data with which to play.

<h3>What level of coding is involved?</h3>
We'll look to make this accessible to those with a wide variety of backgrounds. By then end, we hope you'll be able to take existing computer vision tools (either high-level tools, like those provided by Google AI Platform, or lower level, like someone's GitHub repo), try them out in some new application, and troubleshoot if they do not work. So this will likely be less demanding than CS vision courses (and perhaps a good stepping stone to them), and if you are, for example, comfortable manipulating and analyzing data in some language, and have at least some familiarity with python, this course could work well for you.


  </div>
</div>
</div>

<div class="container sec">
  <h2>Prerequisites</h2>
  <p>This course is intended to attract a broad range of students interested in applying these methods, and in particular students who do not have significant experience taking computer science courses related to computer vision. Project milestones will be tailored so as to be appropriate for each student’s background.

  <ul>
    <li><span class="spanh">Students should have some proficiency in at least one programming language, and should be able to find their way around simple python scripts.</li>
    <li><span class="spanh">Students must have some experience performing statistical analysis on data.</li>
    <li><span class="spanh">A working knowledge in linear algebra, calculus, data science, and statistics (MATH 19, 41, or 51, EDUC400b, 423, 423a, or equivalent) is useful but not strictly required.</li>
  </ul>
</div>

<div class="sechighlight">
<div class="container sec">
  <div class="row">
    <div class="col-md-3">
      <h2>Class time</h2>
      Spring quarter, 2021<br>
      Mo, We 8:30 - 9:50a
    </div>
    <div class="col-md-3">
      <h2>Office hours</h2>
      By appointment<br>
      <a href="mailto:nhaber@stanford.edu">nhaber@stanford.edu</a>, <a href="mailto:vdoch@stanford.edu">vdoch@stanford.edu</a>
    </div>
    <div class="col-md-3">
      <h2>Forum, Zoom link, project submissions</h2>
        Visit our <a href="https://canvas.stanford.edu/courses/138213" target="_blank" rel="noopener noreferrer">Canvas page (Forthcoming!).</a>
    </div>
<!--     <div class="col-md-4">
      <h2>Readings</h2>
      Detailed <a href="readings.html">readings & syllabus</a> page.<br>
      Required readings in <b>bold</b>.<br>
      Contents subject to change.
    </div>
 -->    <div class="col-md-3">
      <h2>Grading</h2>
      Project 50%<br>
      Assignments 20%<br>
      Discussion participation 30%
    </div>
<!--     <div class="col-md-4">
      <h2>Resources</h2>
    <a href="talk_faq.html">Hints/expectations</a> for giving presentations.<br>
    <a href="projects.html">Project timeline</a>.<br>
    Have a look at some helpful <a href="resources.html">resources</a><br>
    for relevant blog posts,<br> environments, and codebases.<br>
    This will grow throughout the quarter<br> as we find new ones!
    </div>
 -->  </div>
</div>
</div>

<div class="container sec">
  <h2>Learning objectives & student responsibilities</h2>
<p>Students should walk away from the course with three general skills:</p>
  <ul>
    <li><span class="spanh">A basic familiarity with a wide variety successful computer vision tools,</li>
    <li><span class="spanh">enough fluency in the field so that, for a particular application, they can attempt to find a suitable computer vision tool, locate a codebase or API for it, and apply it in their setting, and</li>
    <li><span class="spanh">the ability to troubleshoot, and in some cases adapt, their computer vision applications.</li>
  </ul>


  <div id="studentresp">
<p>Students will complete assignments that walk them through the basics of the above learning objectives. In addition, each student will complete a project in which they will apply computer vision to a domain of their choosing.
</p>

<p>For the project, students will scope a potential application of computer vision of interest to them (ideally, applied to their research!). The end deliverable will consist of both (1) a brief writeup of background and motivation for the application, a review of the technique used, and a summary of results (a product ideal for a workshop or conference submission), and (2) a working demonstration of the application (e.g. using a Jupyter notebook). The project has several milestones:
</p>
  <ul>
    <li><span class="spanh">April 15: brief project scoping description</li>
    <li><span class="spanh">Week of May 10: project check-in with instructor.</li>
    <li><span class="spanh">May 27: Project reports due.</li>
    <li><span class="spanh">Week of May 31: Project presentations.</li>
  </ul>

</div>
</div>

<div class="sechighlight">
<div class="container sec">
  <h2>Topics at-a-glance</h2>
  <p>Forthcoming, supplementary readings and further details, as applicable. Topics subject to modifications.</p>
<h3>Unit 1: Getting started</h3>
<p>We take a first look at what is possible with computer vision. Before spending too much time on a full range of possibilities, we take a practical dive into how to get started with ready-made, high-level tools.</p>
  <ul>
    <li>Class 1: Introduction to deep learning and computer vision</li>
    <li>Class 2: Image classification, and using a high-level API for it.</li>
  </ul>
<h3>Unit 2: A whirlwind tour of some current high-performance computer vision systems.</h3>
<p>We look closely at a number of current systems. Here, class will be a mix between lecture and open-ended discussion on potential applications of these tools.</p>
  <ul>
    <li>Class 3: Image detection and segmentation</li>
    <li>Class 4: Pose estimation, gesture, affect, and activity recognition</li>
    <li>Class 5: Generative models</li>
    <li>Class 6: Practicum on using these tools</li>
  </ul>
<h3>Unit 3: The inner workings of a deep learning model</h3>
<p>The goal of this class is not to be able to implement all of the above algorithms ourselves. However, in applying any of these, it is useful to have some intuition for how they work. Fortunately, many current methods have a great deal of commonality. Hence, here we will look in some detail at how image classification works.</p>
  <ul>
    <li>Class 7: Neural network models, loss functions, and optimization</li>
    <li>Class 8: Tensorflow practicum: data formatting, training, validation, hyperparameter tuning, visualization (Assignment 1 due: using a high-level API.)</li>
    <li>Class 9: Deep learning architectures</li>
    <li>Class 10: ImageNet Classification</li>
  </ul>
<h3>Unit 4: Finding useful tools, and getting started with them.</h3>
<p>Sometimes, very standardized industry tools work well for our purposes. However, a much wider variety of tools is available for free, in the form of model implementations in released codebases. In this unit, we will look at how to evaluate computer vision research papers and how to get started with corresponding implementations.</p>
  <ul>
    <li>Class 11: Identifying strong and weak benchmarks.</li>
    <li>Class 12: Reading and evaluating deep learning research papers, part 1 (Assignment 2 Due: Training a neural network on image and video data)</li>
    <li>Class 13: Reading and evaluating deep learning research papers, part 2</li>
    <li>Class 14: Practicum: finding and adapting code on github.</li>
  </ul>
<h3>Unit 5: What can go wrong?</h3>
<p>In this section, we’ll examine common pitfalls in trying to apply computer vision tools.</p>
  <ul>
    <li>Class 15: Common data issues</li>
    <li>Class 16: Common training and test issues</li>
  </ul>

<h3>Unit 6: Applying computer vision to human behavior</h3>
<p>In this unit, we’ll look in some detail at the prospect of applying computer vision in human behavioral work.</p>
  <ul>
    <li>Class 17: Using existing tools to quantify human behavior</li>
    <li>Class 18: Designing human-in-the-loop video analysis tools</li>
  </ul>

</div>
</div>




</html>















